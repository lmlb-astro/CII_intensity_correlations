{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pipeline for uniform FEEDBACK - Herschel - Spitzer data set\n",
    "- Works with data from Nextcloud repository\n",
    "- Objective: get all Herschel and Spitzer data with a uniform resolution, grid and file nomenclature -set by the FEEDBACK [CII] data- for easy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "import astropy.wcs as wcs\n",
    "\n",
    "from reproject import reproject_interp\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User input ####\n",
    "## region\n",
    "region_name = \"RCW79\"\n",
    "path_name = \"../data_CIIcorr/data_FEEDBACK/original/{region}/\".format(region = region_name) ## directory where to get the original data\n",
    "path_intermediate = \"../data_CIIcorr/data_FEEDBACK/intermediate/\" ## directory where to store intermediate results of the processing\n",
    "path_final = \"../data_CIIcorr/data_FEEDBACK/{region}/\".format(region = region_name) ## directory where to get the final data products will be stored\n",
    "\n",
    "## Native resolution of Spitzer and Herschel data\n",
    "#native_res_list = [10.7, 5.6, 17.6, 23.9, 35.2, 1.7, 1.77, 1.88, 1.98] ## first 5: Herschel, last five: Spitzer\n",
    "#name_info_list = [\"Herschel_PACS_160\",  ## first 5: Herschel, last five: Spitzer\n",
    "#             \"Herschel_PACS_70\",\n",
    "#             \"Herschel_SPIRE_250\",\n",
    "#             \"Herschel_SPIRE_350\",\n",
    "#             \"Herschel_SPIRE_500\",\n",
    "#             \"Spitzer_IRAC_3p6\",\n",
    "#             \"Spitzer_IRAC_4p5\",\n",
    "#             \"Spitzer_IRAC_5p8\",\n",
    "#             \"Spitzer_IRAC_8\",\n",
    "#            ]\n",
    "#do_corr = False\n",
    "\n",
    "## for the Herschel 100 micron data\n",
    "native_res_list = [7.0] \n",
    "name_info_list = [\"Herschel_PACS_100\"]\n",
    "do_corr = True\n",
    "corr_facts = [1.66e4]\n",
    "\n",
    "## info for the [CII] data\n",
    "info_CII = 'upGREAT_CII'\n",
    "\n",
    "## initial resolution of the [CII] data\n",
    "init_res_CII = 20.\n",
    "\n",
    "## Target resolution of the final data\n",
    "#target_res = 20. ## arcsec\n",
    "target_res = 36. ## arcsec (the lowest Herschel resolution)\n",
    "#smoothRes = 45. ## arcsec (preparation for GUSTO)\n",
    "\n",
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assumed native resolution = 7.0, for file RCW79_Herschel_PACS_100_large_centered.fits \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Collect the Herschel and Spitzer data\n",
    "file_names_dir = [f for f in listdir(path_name) if isfile(join(path_name, f))]\n",
    "\n",
    "## select files of interest and align with the data file\n",
    "file_names = []\n",
    "for name in name_info_list:\n",
    "    res = name.split(\"_\")\n",
    "    for fname in file_names_dir:\n",
    "        fres = fname.split(\"_\")\n",
    "        if(res[-1] == fres[3]):\n",
    "            file_names.append(fname)\n",
    "            \n",
    "## Ensure that everything worked out well\n",
    "assert len(file_names) == len(name_info_list)\n",
    "\n",
    "## print names and resolution for verification\n",
    "#file_names = sorted(file_names)\n",
    "for i, name in enumerate(file_names):\n",
    "    print(\"The assumed native resolution = {res}, for file {name} \\n\".format(res = native_res_list[i], name = name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of what should be verified when running the script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to be called in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_header(path, file_name):\n",
    "    ## get the data and header\n",
    "    hdu = pyfits.open(path + file_name)\n",
    "    hdu.info()\n",
    "    data, header = hdu[0].data, hdu[0].header\n",
    "    \n",
    "    ## handle RCW 79 file at 100 micron which is not uniform compared to the rest of the data\n",
    "    name_res = file_name.split(\"_\")\n",
    "    if(name_res[0] == 'RCW79' and name_res[3] == '100'):\n",
    "        data, header = hdu[1].data, hdu[1].header\n",
    "    \n",
    "    return data, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data, sigma_conv):\n",
    "    V = data.copy()\n",
    "    V[np.isnan(data)] = 0\n",
    "    VV = gaussian_filter(V, sigma=sigma_conv)\n",
    "    \n",
    "    W = 0*data.copy() + 1\n",
    "    W[np.isnan(data)] = 0\n",
    "    WW = gaussian_filter(W,sigma=sigma_conv)\n",
    "\n",
    "    return VV/WW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End of function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing the [CII] data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ../data_CIIcorr/data_FEEDBACK/original/CII_maps/RCW79_CII_final_res20_grid8_0p5_clean_integrated.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      36   (188, 188)   float32   \n"
     ]
    }
   ],
   "source": [
    "## open the FEEDBACK [CII] fits file\n",
    "hdu = pyfits.open('../data_CIIcorr/data_FEEDBACK/original/CII_maps/{region}_CII_final_res{resCII}_grid8_0p5_clean_integrated.fits'.format(region = region_name,\n",
    "                                                                                                                              resCII = int(init_res_CII + 0.5)\n",
    "                                                                                                                                 ))\n",
    "hdu.info()\n",
    "dataCII = hdu[0].data\n",
    "headerCII = hdu[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pb/xs3f5mtd5bq7lmrql1dj8p040000gn/T/ipykernel_2090/638087385.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  return VV/WW\n"
     ]
    }
   ],
   "source": [
    "## smooth the CII data ##\n",
    "\n",
    "## the pixel size in arcseconds and the Gaussian convolution kernel\n",
    "pix_size_CII = headerCII['CDELT2']*3600. ## 3600 to convert from degree units to arcsecond units\n",
    "sigma_conv_CII = np.sqrt((target_res/2.35)**2 - (init_res_CII/2.35)**2) / pix_size_CII\n",
    "\n",
    "## get the smoothed data\n",
    "data_sm_CII = smooth_data(dataCII, sigma_conv_CII)\n",
    "\n",
    "## update the CII header\n",
    "headerCII['BMAJ'] = target_res / 3600.\n",
    "headerCII['BMIN'] = target_res / 3600.\n",
    "\n",
    "## store the smoothed [CII] \n",
    "if(os.path.exists(path_final) == False):\n",
    "    os.mkdir(path_final)\n",
    "    \n",
    "new_hdu_CII = pyfits.PrimaryHDU(data_sm_CII, headerCII)\n",
    "new_hdu_CII.writeto(\"{path}/{region}_{info}_{res}_{grid}_integrated.fits\".format(path = path_final, \n",
    "                                                                      region = region_name, \n",
    "                                                                      info = info_CII, \n",
    "                                                                      res = int(target_res + 0.5), \n",
    "                                                                      grid = int(pix_size_CII + 0.5)\n",
    "                                                                     ), \n",
    "                    overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing and regridding the Herschel/Spitzer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ../data_CIIcorr/data_FEEDBACK/RCW79//RCW79_upGREAT_CII_36_8_integrated.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      36   (188, 188)   float32   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: FITSFixedWarning: 'celfix' made the change 'Success'. [astropy.wcs.wcs]\n"
     ]
    }
   ],
   "source": [
    "## open the FEEDBACK [CII] fits file\n",
    "#hdu = pyfits.open('../data/data_FEEDBACK/original/CII_maps/{region}_CII_final_res36_grid8_0p5_clean_integrated.fits'.format(region = region_name))\n",
    "hdu = pyfits.open(\"{path}/{region}_{info}_{res}_{grid}_integrated.fits\".format(path = path_final, \n",
    "                                                                      region = region_name, \n",
    "                                                                      info = info_CII, \n",
    "                                                                      res = int(target_res + 0.5), \n",
    "                                                                      grid = int(pix_size_CII + 0.5)\n",
    "                                                                     ))\n",
    "hdu.info()\n",
    "dataCII = hdu[0].data\n",
    "headerCII = hdu[0].header\n",
    "wCII = wcs.WCS(headerCII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ../data_CIIcorr/data_FEEDBACK/original/RCW79/RCW79_Herschel_PACS_100_large_centered.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU     286   ()      \n",
      "  1  image         1 ImageHDU        52   (1659, 1716)   float64   \n",
      "  2  coverage      1 ImageHDU        55   (1659, 1716)   float64   \n",
      "  3  stDev         1 ImageHDU        55   (1659, 1716)   float64   \n",
      "  4  History       1 ImageHDU        23   ()      \n",
      "  5  HistoryScript    1 BinTableHDU     39   81R x 1C   [321A]   \n",
      "  6  HistoryTasks    1 BinTableHDU     46   55R x 4C   [1K, 38A, 1K, 9A]   \n",
      "  7  HistoryParameters    1 BinTableHDU     74   507R x 10C   [1K, 21A, 7A, 31A, 1L, 1K, 1L, 58A, 11A, 35A]   \n",
      "Smoothing the data of RCW79_Herschel_PACS_100_large_centered.fits with an assumed native resolution 7.0\n",
      " -> Done in a total run time of 0.23305797576904297 seconds \n",
      "\n",
      "Starting the regridding on RCW79_Herschel_PACS_100_large_centered.fits\n",
      " -> Done in a total run time of 0.029017210006713867 seconds \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## loop over all data files. First regrid and then smooth the data to the target resolution and grid\n",
    "for i, file_name in enumerate(file_names):\n",
    "    ## get the data file and header information\n",
    "    data, header = get_data_header(path_name, file_name)\n",
    "    \n",
    "    if(do_corr):\n",
    "        data = data*corr_facts[i]\n",
    "        header['BUNIT'] = 'MJy/sr'\n",
    "    \n",
    "    ## get the pixel size in arcseconds\n",
    "    pix_size = header[\"CDELT2\"]*3600. ## 3600 to convert from degree units to arcsecond units\n",
    "    \n",
    "    #### first smooth the data ####\n",
    "    if(native_res_list[i] < target_res):\n",
    "        start_time = time.time()\n",
    "        print(\"Smoothing the data of {file} with an assumed native resolution {res}\".format(file = file_name, res = native_res_list[i]))\n",
    "        \n",
    "        ## calculate the needed Gaussian convolution kernel in pixel size values\n",
    "        sigma_conv = np.sqrt((target_res/2.35)**2 - (native_res_list[i]/2.35)**2) / pix_size ## /2.35 FWHM -> sigma\n",
    "        \n",
    "        ## smooth the data\n",
    "        data_smooth = smooth_data(data, sigma_conv)\n",
    "        \n",
    "        ## store the smoothed data in the intermediate directory\n",
    "        new_hdu = pyfits.PrimaryHDU(data_smooth, header)\n",
    "        new_hdu.writeto(\"{path}smoothed_{file}\".format(path = path_intermediate, file = file_name), overwrite = True)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\" -> Done in a total run time of {time} seconds \\n\".format(time = end_time - start_time))\n",
    "    else:\n",
    "        print(\"No smoothing done \\n\")\n",
    "        new_hdu = pyfits.PrimaryHDU(data, header)\n",
    "        new_hdu.writeto(\"{path}smoothed_{file}\".format(path = path_intermediate, file = file_name), overwrite = True)\n",
    "        \n",
    "    \n",
    "    #### perform the regridding on the smoothed data ####\n",
    "    start_time = time.time()\n",
    "    print(\"Starting the regridding on {file}\".format(file = file_name))\n",
    "    \n",
    "    ## open HDU to perform regridding on\n",
    "    hdu = pyfits.open(\"{path}smoothed_{file}\".format(path = path_intermediate, file = file_name))\n",
    "    \n",
    "    ## perform reprojection on the [CII] grid\n",
    "    array, footprint = reproject_interp(hdu, headerCII)\n",
    "    \n",
    "    ## prepare the header to store the regridded map\n",
    "    new_header = headerCII.copy()\n",
    "    new_header['BUNIT'] = 'MJy/sr'\n",
    "    new_header['LINE'] = name_info_list[i]\n",
    "    \n",
    "    ## save the regridded map\n",
    "    new_hdu = pyfits.PrimaryHDU(array, new_header)\n",
    "    if(os.path.exists(path_final) == False):\n",
    "        os.mkdir(path_final)\n",
    "    new_hdu.writeto(\"{path}/{region}_{info}_{res}_{grid}.fits\".format(path = path_final, region = region_name, info = name_info_list[i], \n",
    "                                                                      res = int(target_res + 0.5), grid = int(headerCII[\"CDELT2\"]*3600. + 0.5)\n",
    "                                                                     ))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\" -> Done in a total run time of {time} seconds \\n\".format(time = end_time - start_time))\n",
    "    print(\" \")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
